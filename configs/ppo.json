{
  "algo": "ppo",
  "agent": "ppo",
  "buffer": "runner",
  "lam": 0.95,
  "actor_lr": 3e-4,
  "critic_lr": 3e-4,
  "max_episode_len": 1000,
  "eval_freq": 8192,
  "eval_episodes": 5,
  "hidden_size": 128,
  "log_freq": 1,
  "steps_per_epoch": 2048,
  "nb_optim_iters": 10,
  "clip_ratio": 0.2,
  "batch_size": 32,
  "ent_coef": 0,
  "vf_coef": 0.5
}